### Business | Bartleby

#### 商业 | Bartleby 面部分析是否应该帮助公司决定招聘对象？

一篇新论文指出，一张照片就能让招聘人员了解求职者的性格 2025年11月6日 

- 想象一下，你去参加面试，还没开口，就被告知因为你的长相不符合要求而落选。你会认为这是歧视，甚至可能考虑提起诉讼。
- 但如果偏见并非原因呢？如果你的脸真的能提供关于你工作表现的有效线索呢？宾夕法尼亚大学的马里乌斯·根泽尔（Marius Guenzel）及其合作者最近发表的一篇研究论文的核心问题正是这个问题。这种可能性引发了关于算法决策以及人类如何感知公平的更广泛的思考。性格评估是招聘流程中公认的一部分。通常情况下，这些评估包括求职者填写调查问卷，并猜测什么样的答案才算好答案。然而，此前的研究表明，人格类型可以从面部特征中编码，人工智能（AI）也能识别这些特征。因此，根泽尔先生及其合作者使用一种算法分析了96000名MBA毕业生的照片，并提取出他们所谓的“照片五大人格特质”（Photo BigFive）——他们将“亲和力”（agreeableness）、“尽责性”（conscientiousness）、“外向性”（extraversion）、“神经质”（neuroticism）和“开放性”（openiness）这五大人格特质重新命名。（在你照镜子之前，你还不清楚人工智能究竟看到了什么。）然后，他们利用这些毕业生的就业市场数据，检验“照片五大人格特质”是否具有任何预测能力。他们的结论是肯定的：面部分析可以有效地预测一个人的MBA毕业后的收入和跳槽倾向等。当然，也存在一些需要注意的地方。“照片五大人格特质”的预测能力不应被夸大；作者指出，它只是对候选人信息的一种补充。人工智能面部分析领域尚属新兴，过去也曾是方法论争论的焦点。即便技术完美无缺，其普及应用也可能进展缓慢。反歧视法意味着，基于面部特征做出任何决定都存在明显的法律风险。麻省理工学院斯隆管理学院的马尼什·拉加万指出，企业对使用人工智能进行面部分析持谨慎态度（尽管他更担心的是，聊天机器人对候选人简历或领英个人资料的摘要会受到偏见的影响）。但假设所有这些反对意见都可以克服。如果你的面部特征能够向潜在雇主提供有用的信息，且不会基于受保护的特征进行歧视，那么企业就会有强烈的动机去分析它。然而，仍然存在一些问题。作者举例说：“在白人男性求职者中，筛选掉那些面部特征预示着性格不太理想的人是否合乎道德？”你可能会认为这样做没问题。毕竟，很多决定都是基于外貌做出的。例如，在招聘中存在身高溢价，这意味着个子高的人比个子矮的人更容易被选中。有人认为，基于面部特征的分析比奖励教育程度等因素的流程更符合精英选拔原则。耶鲁大学管理学院的凯利·舒（Kelly Shue）是这篇新论文的作者之一，她表示，他们目前正在研究人工智能面部分析能否为贷款机构提供关于借款人还款倾向的有用线索。对于那些无法获得信贷的人来说，这可能是一件好事。然而，即使撇开偏见风险不谈，还有其他一些重大问题。有些显而易见：总体模式并不能预测个人的表现。另一些则更为隐蔽。教练和自助大师组成的行业正是建立在这样一种理念之上：人们可以控制和调节自己的行为。如果你的脸仍然会传递出你是个业余爱好者的信号，那么自我提升又有什么意义呢？你对这种前景的反应也反映了你对人工智能和公平性的认知。人们是否保留自主感至关重要。无论算法多么先进，在招聘过程中，候选人赢得面试官青睐的机会——以及面试官自行决定是否与某人共事的机会——始终都备受重视。拉加万先生认为，如果存在清晰的因果逻辑，人们更容易接受基于不可改变特征的决定。例如，年轻驾驶员支付更高的汽车保险费，或者老年人支付更高的医疗保健费用，都有合理的统计依据。对许多人来说，面部分析会令人质疑。

### Deepseek总结


好的，这篇文章探讨了一个非常前沿且富有争议的话题：**使用人工智能进行面部分析来评估求职者的性格，并预测其工作表现。** 文章的核心在于揭示这项技术的潜在可能性和它引发的巨大伦理、法律及社会担忧。

以下是文章的详细解释：

### 1. 核心研究：面部分析能预测工作表现吗？

* **研究内容**：宾夕法尼亚大学的研究者使用AI算法分析了96,000名MBA毕业生的照片，试图从面部特征中提取出与“五大人格特质”（亲和性、尽责性、外向性、神经质、开放性）相关的信息，他们称之为“照片五大人格特质”。
* **研究发现**：研究发现，这些通过面部分析得出的特质，能够在一定程度上**预测**这些毕业生毕业后的收入水平和跳槽倾向。
* **重要前提**：研究者强调，这种预测能力**不应被夸大**，它只能作为对候选人其他信息（如简历、面试表现）的一种**补充**，而非决定性因素。

### 2. 潜在优势：为什么企业可能想用它？

文章假设所有问题都能解决，那么这项技术可能带来以下好处：

* **效率与信息增量**：能为企业提供传统面试和问卷无法捕捉的额外信息。
* **更“精英”的选拔？**：有人论证，相比看重学历背景（这可能与家庭出身有关），基于面部特征的分析可能更“客观”地关注个人内在特质，更符合精英选拔原则。
* **更广泛的应用**：例如，在信贷领域，或许能为无法提供信用记录的人提供关于其还款意愿的线索，帮助他们获得贷款。

### 3. 巨大的争议与风险（文章的重点）

尽管有潜在优势，文章花了更多篇幅来阐述其带来的多重问题和挑战：

* **法律风险**：这是最直接的障碍。基于面部特征做决定，极易触犯反歧视法，因为算法可能（有意或无意地）针对种族、性别、年龄等受保护的特征进行歧视。
* **伦理困境**：

  * **“自主感”的丧失**：如果性格由你的脸“注定”，那么个人努力、成长和自我提升还有什么意义？这会剥夺人们的自主感和能动性。
  * **公平性质疑**：我们是否能接受基于一个我们无法轻易改变的生理特征（长相）来做重要的人生决定（如求职、贷款）？文章用保险费做对比：年轻司机保费高是因为有清晰的因果逻辑（事故率统计），而面部分析的因果逻辑非常模糊且令人不安。
  * **固化偏见**：它可能奖励某种“理想”面相，从而固化一种单一、可能带有偏见的标准，排斥多样性。
* **方法论问题**：

  * **群体趋势 vs. 个人表现**：研究揭示的是群体统计趋势，但无法准确预测**某一个具体个人**的实际工作表现。一个面相“看起来”不尽责的人，完全可能是一个非常优秀的员工。
  * **技术不成熟**：该领域尚属新兴，其方法论在过去存在争议，准确性远非完美。
  * **企业的谨慎**：由于潜在的声誉和法律风险，许多企业对采用这项技术持谨慎态度。

### 4. 文章的深层思考

这篇文章不仅仅是报道一项研究，更是通过这个极端案例，引发读者对一系列根本问题的思考：

* **什么是真正的公平？** 是给每个人同样的标准，还是考虑每个人的独特背景和潜力？
* **技术在决策中的边界在哪里？** 当算法能提供看似“客观”的数据时，我们是否应该放弃人类的主观判断和同理心？
* **人性的本质是什么？** 我们是否愿意生活在一个被外部算法“定义”和“预测”的世界里？

### 总结

总而言之，这篇文章描绘了这样一个图景：**一项技术上可能有一定预测能力，但在伦理、法律和社会层面存在巨大隐患的工具。** 它像一把双刃剑，虽然承诺提升决策效率，但其代价可能是牺牲个人的自主性、社会的公平性，并可能打开歧视和偏见的新潘多拉魔盒。你对这项技术的态度，很大程度上反映了你对于**技术、公平与人性**之间关系的根本看法。

#### Should facial analysis help determine whom companies hire?

A new paper suggests a photo can tell a recruiter much about anapplicant’s personalityNovember 6th 2025Imagine appearing for a job interview and, without saying a single word,being told that you are not getting the role because your face didn’t fit. Youwould assume discrimination, and might even contemplate litigation.But what if bias was not the reason? What if your face gave genuinely usefulclues about your probable performance at work? That question is at the heartof a recent research paper from Marius Guenzel of the University ofPennsylvania and his co-authors. The possibility that it does raises largerquestions about algorithmic decision-making and how humans perceivefairness.Personality assessments are an accepted part of recruitment processes. Theynormally involve candidates taking surveys and guessing what counts as agood answer. Yet previous research suggests that personality types can beencoded in facial features, and that artificial intelligence (AI) can spot them.So Mr Guenzel and his co-authors used an algorithm to analyse the picturesof 96,000 MBA graduates, and extract what they call the “Photo BigFive”—as they rename the Big Five personality traits of agreeableness,conscientiousness, extraversion, neuroticism and openness. (Before youhead to the mirror, it’s not obvious what the AI is seeing.)They then used data on these individuals’ labour-market outcomes to seewhether the Photo Big Five had any predictive power. The answer, theyconclude, is yes: facial analysis has useful things to say about a person’spost-MBA earnings and propensity to move jobs, among other things.There are plenty of caveats. The predictive power of the Photo Big Fiveshouldn’t be exaggerated; the authors say it is only an incremental source ofinformation on candidates. The field of AI facial analysis is young, and hasbeen at the centre of methodological firestorms in the past. And even iftechniques were flawless, adoption is likely to be slow. Anti-discriminationlaws mean that there are obvious legal risks associated with making anydecisions based on facial characteristics. Manish Raghavan of the MITSloan School of Management notes that companies are wary of using AI forfacial analysis (though he worries more about bias infecting chatbotsummaries of candidates’ cvs or LinkedIn profiles.)But suppose that all these objections were surmountable. If your face couldtell a prospective employer something useful, without discriminating ongrounds of protected characteristics, then firms would have a strongincentive to analyse it. There would still be questions, though. The authorsgive an example: “Among white male job candidates, is it ethical to screenout individuals whose faces predict less desirable personalities?”You could make the case that this would be fine. After all, plenty ofdecisions are already being taken on the basis of physical appearance. Thereis a height premium in hiring, for example, which makes it more likely that ataller person will get chosen than a shorter one. Some might argue that facebased analysis is more meritocratic than processes which reward, say,educational attainment. Kelly Shue of the Yale School of Management, oneof the new paper’s authors, says they are now looking at whether AI facialanalysis can give lenders useful clues about a person’s propensity to repayloans. For people without access to credit, that could be a blessing.Even setting aside the risk of bias, though, there are other big concerns.Some are obvious: aggregate patterns do not tell you how an individual willperform. Others are more insidious. An industry of coaches and self-helpgurus is built on the idea that it is possible to control and modulate yourbehaviour. What’s the point in self-improvement if your face is still going togive off the same signal that you’re a dilettante?How you react to this prospect also tells you something about AI andperceptions of fairness. It matters whether people retain a sense of agency.However good the algorithms get, a chance for a candidate to win over ahuman interviewer in a hiring process—and for an interviewer to decide forthemselves if they want to work with someone—is likely to always bevalued.Mr Raghavan argues that people are more prepared to accept decisions basedon immutable characteristics if there is clear causal logic. There arereasonable statistical grounds for younger drivers to pay higher carinsurance premiums, for example, or for older people to pay more for healthcare. For many, facial analysis will raise eyebrows.
